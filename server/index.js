import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import { z } from 'zod';
import dayjs from 'dayjs';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import { v4 as uuidv4 } from 'uuid';

import { ChatOpenAI, OpenAIEmbeddings } from '@langchain/openai';
import { HNSWLib } from '@langchain/community/vectorstores/hnswlib';
import { Document } from '@langchain/core/documents';
import {
  StateGraph,
  START,
  END,
  MessagesAnnotation,
  MemorySaver,
  Annotation,
} from '@langchain/langgraph';
import { AIMessage, HumanMessage, SystemMessage } from '@langchain/core/messages';

/**
 * Multi-Agente de anÃ¡lise de sonhos com PERSONAS + Streaming (SSE)
 * Personae: Jungian, Narrative, Cognitive
 * Modos: auto (roteador escolhe), specific (forÃ§a uma), ensemble (3 personae + sÃ­ntese)
 *
 * Endpoints:
 * POST /chat      -> resposta Ãºnica (JSON)
 * POST /chat/stream -> streaming SSE (text/event-stream)
 */

// ===== infra =====
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const DATA_DIR = path.join(__dirname, 'data');
const DREAMS_JSON = path.join(DATA_DIR, 'dreams.json');
const INDEX_DIR = path.join(DATA_DIR, 'dreams.index');
await fs.mkdir(DATA_DIR, { recursive: true }).catch(() => {});
try { await fs.access(DREAMS_JSON); } catch { await fs.writeFile(DREAMS_JSON, '[]'); }

const MODEL = process.env.MODEL || 'gpt-4.1-mini';
const EMBED_MODEL = process.env.EMBED_MODEL || 'text-embedding-3-small';

const llm = new ChatOpenAI({ model: MODEL, temperature: 0.2 });
const embeddings = new OpenAIEmbeddings({ model: EMBED_MODEL });

let vectorStore;
async function loadVectorStore() {
  try {
    vectorStore = await HNSWLib.load(INDEX_DIR, embeddings);
  } catch (e) {
    console.log('Index not found. Trying to build from dreams.json...');
    const dreams = await readDreams();
    if (dreams.length > 0) {
      console.log(`Found ${dreams.length} dreams. Building index...`);
      const dreamDocs = dreams.map(d => new Document({
        pageContent: d.text,
        metadata: { id: d.id, date: d.date, tags: d.tags }
      }));
      vectorStore = await HNSWLib.fromDocuments(dreamDocs, embeddings);
      await vectorStore.save(INDEX_DIR);
      console.log('Index built and saved.');
    } else {
      console.log('No dreams found in dreams.json. Vector store will be created on first addition.');
    }
  }
}
await loadVectorStore();

async function readDreams() { return JSON.parse(await fs.readFile(DREAMS_JSON, 'utf8')); }
async function writeDreams(arr) { await fs.writeFile(DREAMS_JSON, JSON.stringify(arr, null, 2)); }

// ===== Tools: salvar e buscar sonhos =====
const storeDreamSchema = z.object({
  text: z.string().describe('Texto do sonho'),
  date: z.string().optional().describe('AAAA-MM-DD'),
  tags: z.array(z.string()).optional(),
});
async function storeDream({ text, date, tags }) {
  const dreams = await readDreams();
  const id = uuidv4();
  const record = { id, text, date: date || dayjs().format('YYYY-MM-DD'), tags: tags || [], createdAt: new Date().toISOString() };
  dreams.push(record);
  await writeDreams(dreams);

  const doc = new Document({ pageContent: text, metadata: { id, date: record.date, tags: record.tags } });

  if (vectorStore) {
    await vectorStore.addDocuments([doc]);
  } else {
    vectorStore = await HNSWLib.fromDocuments([doc], embeddings);
  }

  await vectorStore.save(INDEX_DIR);
  return record;
}

async function searchDreams({ query, k = 3 }) {
  if (!vectorStore) {
    return [];
  }
  const results = await vectorStore.similaritySearch(query, k);
  return results.map(r => ({ text: r.pageContent, ...r.metadata }));
}

// ===== Estado do grafo (modo JSON) =====
const GraphAnnotation = Annotation.Root({
  ...MessagesAnnotation.spec,
  intent: Annotation(),
  action: Annotation(),
  mode: Annotation(),        // 'auto' | 'specific' | 'ensemble'
  persona: Annotation(),     // 'jung' | 'narrative' | 'cognitive'
  contextDocs: Annotation(), // resultados de busca
});

function lastUser(state) {
  const last = [...(state.messages || [])].reverse().find(m => m._getType?.() === 'human');
  return last?.content || '';
}

// ===== Roteador de intenÃ§Ã£o (store/search/analyze) =====
async function routerNode(state) {
  const txt = lastUser(state).toLowerCase();
  let action = 'analyze';
  if (/(salvar|guardar|registrar|armazenar|gravar|adicionar)/.test(txt)) action = 'store';
  if (/(busca|buscar|procurar|achar|similar|encontrar|listar)/.test(txt)) action = 'search';
  return { action };
}

// ===== PrÃ©-busca de contexto (para anÃ¡lise) =====
async function retrieveNode(state) {
  const q = lastUser(state);
  const docs = await searchDreams({ query: q, k: 3 });
  return { contextDocs: docs };
}

// ===== Roteador de PERSONA =====
const PersonaChoiceSchema = z.object({ persona: z.enum(['jung','narrative','cognitive']) });
async function personaRouterNode(state) {
  const mode = state.mode || 'auto';
  if (mode === 'specific' && state.persona) return { persona: state.persona };
  if (mode === 'ensemble') return { persona: 'ensemble' };

  // auto -> deixar o LLM decidir
  const system = new SystemMessage(`VocÃª Ã© um roteador que escolhe a melhor PERSONA para analisar um sonho.
  Regras:
  - 'jung' quando o foco for sÃ­mbolos, arquÃ©tipos, sombra, anima/animus, individuaÃ§Ã£o, mitologia.
  - 'narrative' quando o foco for enredo, personagem, conflito, transformaÃ§Ã£o, ponto de vista.
  - 'cognitive' quando o foco for emoÃ§Ã£o, ansiedade, memÃ³ria, aprendizagem, problemas cotidianos, regulaÃ§Ã£o.
  Responda APENAS com JSON: {"persona":"jung|narrative|cognitive"}`);
  const input = new HumanMessage(`SONHO: ${state._userText || ''}`);
  const choice = await llm.withStructuredOutput(PersonaChoiceSchema).invoke([system, input]);
  return { persona: choice.persona };
}

// ===== Prompts por PERSONA =====
function buildContextBlock(ctx = []) {
  if (!ctx.length) return '(sem similares)';
  return ctx.map((c, i) => `â€” Similar #${i+1} (${c?.date || 's/ data'}; id=${c?.id||'n/a'}):
${c?.text}`).join(`

`);
}

function jungPrompt(userText, ctxBlock) {
  return [
    new SystemMessage(`Persona: ANALISTA JUNGIANO. Estilo: simbÃ³lico, arquÃ©tipos, mitopoiese, sombra, anima/animus.
- ForneÃ§a mÃºltiplas hipÃ³teses, sem determinismo.
- NÃ£o faÃ§a diagnÃ³sticos mÃ©dicos.
Estrutura:
1) SÃ­mbolos centrais e arquÃ©tipos possÃ­veis
2) RelaÃ§Ã£o com processo de individuaÃ§Ã£o e tensÃµes psÃ­quicas
3) Ecos mitolÃ³gicos e culturais (se houver)
4) RelaÃ§Ãµes com sonhos similares
5) Perguntas para aprofundar`),
    new HumanMessage(`SONHO: ${userText}`),
    new HumanMessage(`SIMILARES:
${ctxBlock}`),
  ];
}

function narrativePrompt(userText, ctxBlock) {
  return [
    new SystemMessage(`Persona: ANALISTA NARRATIVO. Foco: enredo, personagens, conflito, viradas, metÃ¡foras vividas.
- Destacar estrutura (setup â†’ conflito â†’ clÃ­max â†’ resoluÃ§Ã£o/abertura).
- Sugerir reescritas simbÃ³licas.
Estrutura:
1) Mapa de enredo (setup/conflito/clÃ­max/desfecho)
2) Personagens e forÃ§as em jogo
3) MetÃ¡foras e temas recorrentes
4) RelaÃ§Ãµes com sonhos similares
5) Experimentos narrativos (se o sonhador revisitasse a cenaâ€¦)`),
    new HumanMessage(`SONHO: ${userText}`),
    new HumanMessage(`SIMILARES:
${ctxBlock}`),
  ];
}

function cognitivePrompt(userText, ctxBlock) {
  return [
    new SystemMessage(`Persona: ANALISTA COGNITIVO-AFETIVO. Foco: emoÃ§Ã£o, ansiedade, memÃ³ria, aprendizagem, regulaÃ§Ã£o.
- Linguagem prÃ¡tica, hipÃ³teses parcimoniosas, vieses cognitivos, pistas de estresse.
- Oferecer exercÃ­cios leves de autorreflexÃ£o (nÃ£o clÃ­nicos).
Estrutura:
1) EmoÃ§Ãµes predominantes e gatilhos provÃ¡veis
2) HipÃ³teses de funÃ§Ã£o do sonho (consolidaÃ§Ã£o/ensaio/gestÃ£o de ameaÃ§a)
3) RelaÃ§Ãµes com rotina/estressores atuais
4) RelaÃ§Ãµes com sonhos similares
5) Pequenos experimentos/diÃ¡rio de bordo para prÃ³ximos dias`),
    new HumanMessage(`SONHO: ${userText}`),
    new HumanMessage(`SIMILARES:
${ctxBlock}`),
  ];
}

// ===== NÃ³s store/search (modo nÃ£o-stream) â€” reutilizam grafo JSON =====
async function storeNode(state) {
  const prompt = [
    new SystemMessage(`Extraia JSON do pedido do usuÃ¡rio. Campos: text, date (opcional AAAA-MM-DD), tags (opcional array). Responda APENAS JSON.`),
    new HumanMessage(state._userText || ''),
  ];
  const parsed = await llm.withStructuredOutput(storeDreamSchema).invoke(prompt);
  const rec = await storeDream(parsed);
  return { messages: [ new AIMessage(`âœ… Sonho salvo (id ${rec.id}, ${rec.date}). Tags: ${(rec.tags||[]).join(', ')||'â€”'}`) ] };
}

async function searchNode(state) {
  const qPrompt = [ new SystemMessage(`Gere uma query curta para buscar sonhos similares. Responda apenas a query.`), new HumanMessage(state._userText || '') ];
  const q = (await llm.invoke(qPrompt)).content;
  const hits = await searchDreams({ query: q, k: 3 });
  const out = hits.length
    ? hits.map((h,i)=> `#${i+1} (${h.date||'s/ data'}; id=${h.id||'n/a'})
${h.text.slice(0,400)}${h.text.length>400?'â€¦':''}`).join(`

`)
    : 'Nenhum similar encontrado.';
  return { messages: [ new AIMessage(`ðŸ”Ž Similares

${out}`) ] };
}

// ===== Graph (modo JSON, /chat) =====
const graph = new StateGraph(GraphAnnotation)
  .addNode('router', routerNode)
  .addNode('retrieve', retrieveNode)
  .addNode('personaRouter', personaRouterNode)
  .addNode('store', storeNode)
  .addNode('search', searchNode)
  // Dummies: nÃ³s finais da anÃ¡lise serÃ£o tratados no endpoint stream; no /chat simples, usamos persona=cada e llm.invoke
  .addEdge(START, 'router')
  .addConditionalEdges('router', (s)=> s.action || 'analyze', {
    store: 'store',
    search: 'search',
    analyze: 'retrieve',
  })
  .addEdge('store', END)
  .addEdge('search', END)
  .addEdge('retrieve', 'personaRouter')
  .addEdge('personaRouter', END);

const memory = new MemorySaver();
const app = graph.compile({ checkpointer: memory });

// ===== HTTP =====
const server = express();

// CORS Configuration
if (process.env.CORS_DISABLED !== 'true') {
  const corsOptions = {
    origin: '*', // Allow all origins
    methods: ['GET', 'POST', 'OPTIONS'],
    allowedHeaders: ['Content-Type', 'Authorization'],
  };
  server.use(cors(corsOptions));
  console.log('CORS enabled.');
} else {
  console.log('CORS disabled by environment variable.');
}

server.use(express.json());

// Resposta Ãºnica (JSON), Ãºtil para fallback sem streaming
server.post('/chat', async (req, res) => {
  try {
    const { messages = [], threadId, mode, persona } = req.body || {};

    const mapped = messages.map((m) => {
      if (m.role === 'system') return new SystemMessage(m.content);
      if (m.role === 'assistant') return new AIMessage(m.content);
      return new HumanMessage(m.content);
    });
    const userText = [...mapped].reverse().find(m => m._getType?.() === 'human')?.content || '';

    const result = await app.invoke(
      { messages: mapped, mode: mode || 'auto', persona, _userText: userText },
      { configurable: { thread_id: threadId || uuidv4() } }
    );

    // Se aÃ§Ã£o nÃ£o for analyze, resposta jÃ¡ veio
    if (result.action === 'store' || result.action === 'search') {
      const last = result.messages[result.messages.length - 1];
      return res.json({
        threadId: (result.configurable && result.configurable.thread_id) || threadId,
        message: { role: 'assistant', content: last.content },
        persona: result.persona || persona || 'auto',
        mode: result.mode || mode || 'auto',
      });
    }

    // analyze: gerar resposta por persona Ãºnica
    const ctxBlock = buildContextBlock(result.contextDocs || []);
    const chosen = (result.persona === 'ensemble') ? 'jung' : (result.persona || 'jung');
    const promptBy = { jung: jungPrompt, narrative: narrativePrompt, cognitive: cognitivePrompt }[chosen];
    const out = await llm.invoke(promptBy(userText, ctxBlock));
    res.json({
      threadId: (result.configurable && result.configurable.thread_id) || threadId,
      message: { role: 'assistant', content: out.content },
      persona: chosen,
      mode: result.persona === 'ensemble' ? 'ensemble' : (result.mode || mode || 'auto'),
    });
  } catch (e) {
    console.error(e);
    res.status(500).json({ error: String(e?.message || e) });
  }
});

// ===== Streaming SSE =====
server.post('/chat/stream', async (req, res) => {
  try {
    const { messages = [], threadId, mode, persona } = req.body || {};

    // SSE headers
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');

    const send = (obj) => {
      res.write(`data: ${JSON.stringify(obj)}

`);
    };

    const mapped = messages.map((m) => {
      if (m.role === 'system') return new SystemMessage(m.content);
      if (m.role === 'assistant') return new AIMessage(m.content);
      return new HumanMessage(m.content);
    });
    const userText = [...mapped].reverse().find(m => m._getType?.() === 'human')?.content || '';

    const result = await app.invoke(
      { messages: mapped, mode: mode || 'auto', persona, _userText: userText },
      { configurable: { thread_id: threadId || uuidv4() } }
    );

    const finalThread = (result.configurable && result.configurable.thread_id) || threadId;
    send({ event: 'meta', threadId: finalThread, mode: result.mode || mode || 'auto', persona: result.persona || persona || 'auto' });

    // store/search -> nÃ£o faz sentido tokenizar; envia uma mensagem Ãºnica
    if (result.action === 'store' || result.action === 'search') {
      const last = result.messages[result.messages.length - 1];
      send({ event: 'message', content: last.content });
      send({ event: 'done' });
      return res.end();
    }

    // analyze -> stream persona(s)
    const ctxBlock = buildContextBlock(result.contextDocs || []);

    async function streamPrompt(prompt, label) {
      send({ event: 'persona', persona: label });
      let acc = '';
      for await (const chunk of llm.stream(prompt)) {
        const text = typeof chunk?.content === 'string' ? chunk.content : Array.isArray(chunk?.content) ? chunk.content.join('') : '';
        if (text) {
          acc += text;
          send({ event: 'token', text });
        }
      }
      send({ event: 'section_end', persona: label });
      return acc;
    }

    if ((result.persona || persona) === 'ensemble') {
      // 1) stream das trÃªs
      const p1 = await streamPrompt(jungPrompt(userText, ctxBlock), 'jung');
      const p2 = await streamPrompt(narrativePrompt(userText, ctxBlock), 'narrative');
      const p3 = await streamPrompt(cognitivePrompt(userText, ctxBlock), 'cognitive');

      // 2) sÃ­ntese
      send({ event: 'persona', persona: 'synthesis' });
      const synthPrompt = [
        new SystemMessage(`VocÃª Ã© um sintetizador. Combine anÃ¡lises de trÃªs especialistas (Jung, Narrativo, Cognitivo).
- Destacar convergÃªncias e divergÃªncias.
- Fechar com 3 a 5 perguntas Ãºteis ao sonhador.
Responda de forma concisa e estruturada.`),
        new HumanMessage([p1, p2, p3].join(`

â€” â€” â€”

`)),
      ];
      await streamPrompt(synthPrompt, 'synthesis');
      send({ event: 'done' });
      return res.end();
    } else {
      const chosen = (result.persona || persona || 'jung');
      const promptBy = { jung: jungPrompt, narrative: narrativePrompt, cognitive: cognitivePrompt }[chosen];
      await streamPrompt(promptBy(userText, ctxBlock), chosen);
      send({ event: 'done' });
      return res.end();
    }
  } catch (e) {
    // Em caso de erro, ainda tenta enviar pelo canal SSE
    try { res.write(`data: ${JSON.stringify({ event: 'error', error: String(e?.message || e) })}

`); } catch {}
    try { res.end(); } catch {}
  }
});

const PORT = process.env.PORT || 3031;
server.listen(PORT, () => {
  console.log(`ðŸŸ¢ Personas server (SSE) on http://localhost:${PORT}`);
});
